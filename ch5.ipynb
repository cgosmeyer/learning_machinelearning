{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "import sklearn\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Example of using the `score` method to evaluate supervised model\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "# create a synthetic dataset\n",
    "X, y = make_blobs(random_state=0)\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) \n",
    "# instantiate a model and fit it to the training set\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "# evaluate the model on the test set\n",
    "print(\"Test set score: {:.2f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [ 0.96078431  0.92156863  0.95833333]\n"
     ]
    }
   ],
   "source": [
    "# Try cross-validation in scikit-learn\n",
    "# Three-fold cross-validation is the default.\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "iris = load_iris()\n",
    "logreg = LogisticRegression()\n",
    "scores = cross_val_score(logreg, iris.data, iris.target) \n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [ 1.          0.96666667  0.93333333  0.9         1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Try changing to 5-fold\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=5) \n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Summarize accuracies by computing the mean.\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 112 size of test set: 38\n",
      "Best score: 0.97\n",
      "Best parameters: {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Try implementing a grid search\n",
    "# naive grid search implementation\n",
    "from sklearn.svm import SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "print(\"Size of training set: {} size of test set: {}\".format(\n",
    "          X_train.shape[0], X_test.shape[0]))\n",
    "best_score = 0\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]: \n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters, train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluate the SVC on the test set\n",
    "        score = svm.score(X_test, y_test)\n",
    "        # if we got a better score, store the score and parameters \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "print(\"Best score: {:.2f}\".format(best_score)) \n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 84 size of validation set: 28 size of test set: 38\n",
      "\n",
      "Best score on validation set: 0.96\n",
      "Best parameters:  {'C': 10, 'gamma': 0.001}\n",
      "Test set score with best parameters: 0.92\n"
     ]
    }
   ],
   "source": [
    "# More sophisticatedly, split the data in training, validation, and test sets.\n",
    "from sklearn.svm import SVC\n",
    "# split data into train+validation set and test set \n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "iris.data, iris.target, random_state=0)\n",
    "# split train+validation set into training and validation sets \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_trainval, y_trainval, random_state=1)\n",
    "print(\"Size of training set: {} size of validation set: {} size of test set:\"\n",
    "\" {}\\n\".format(X_train.shape[0], X_valid.shape[0], X_test.shape[0])) \n",
    "best_score = 0\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]: \n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters, train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluate the SVC on the validation set\n",
    "        score = svm.score(X_valid, y_valid)\n",
    "        # if we got a better score, store the score and parameters \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "            \n",
    "# rebuild a model on the combined training and validation set, \n",
    "# and evaluate it on the test set\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score)) \n",
    "print(\"Best parameters: \", best_parameters)\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Still more sophisticatedly, split the dataset 3 ways and use cross-validation\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]: \n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    # for each combination of parameters, # train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        # perform cross-validation\n",
    "        scores = cross_val_score(svm, X_trainval, y_trainval, cv=5) \n",
    "        # compute mean cross-validation accuracy\n",
    "        score = np.mean(scores)\n",
    "        # if we got a better score, store the score and parameters \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "# rebuild a model on the combined training and validation set \n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "{'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In scikit-learn there are built-in methods to perform grid search with cross-validation\n",
    "# Need specify parameter grid using a dictionary\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        iris.data, iris.target, random_state=0)\n",
    "# The grid_search object behaves like a classifier and can call predict, fit, and score on it\n",
    "# But when call fit, it will run cross-validation for each combination of parameters\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.97\n",
      "Best parameters: {'C': 100, 'gamma': 0.01}\n",
      "Best cross-validation score: 0.97\n",
      "Best estimator:\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
